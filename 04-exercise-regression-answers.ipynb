{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 04: Regression I\n",
    "\n",
    "\n",
    "Welcome to the fourth exercise for Applied Machine Learning. \n",
    "\n",
    "Your objectives for this session are to: \n",
    "- learn the basics of the fitting a model to data, \n",
    "- fit linear regression and logistic regression models with `sklearn`, and\n",
    "- interpret the outputs of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "### Part 1: Fitting a model to data with `sklearn`\n",
    "\n",
    "Last time we looked into `sklearn` and how to use this python library to implement decision trees. Today we will use the same library to implement linear and logstic regression. \n",
    "\n",
    "Linear regression predicts a continuous value for a variable based on the value of another variable. The classic ***regression*** task with a continuous target variable.\n",
    "\n",
    "Logistic regression predicts a class value for a a variable based on the value of another variable. Although the model has regression in its name, logistic regression is for ***classification*** tasks with a categorical target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import our libraries for today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember what we learned last week about `sklearn`? We need to train (or \"fit\") a pre-programmed algorithm (or \"estimator\") to some data so that it can be used make predictions on new data.\n",
    "\n",
    "Like last time, the data should be structured as two arrays:\n",
    "\n",
    "* `X` = 2D array of samples/instances/observations (sometimes called the \"samples matrix,\" \"design matrix,\" or \"features matrix\"), where instances are represented as rows and features/attributes are represented as columns.\n",
    "\n",
    "* `y` = 1D array where the ith entry corresponds to the target of the ith sample (row) of X. For regression tasks the target values are real numbers. For classification tasks the target values are integers (or any other discrete set of values). \n",
    "\n",
    "\n",
    "Let's look at an example with the same basic structure as last week's example, but this time with just one attribute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.993\n"
     ]
    }
   ],
   "source": [
    "# define our example model - we will use the Linear Regression model\n",
    "example_lr = LinearRegression() \n",
    "\n",
    "# make some fake samples for X — 4 instances, 1 atrribute\n",
    "X = [[1],  \n",
    "     [11],\n",
    "     [21],\n",
    "     [31]]\n",
    "\n",
    "# make some fake target values for y - continuous numeric values because regression!\n",
    "y = [2.5, 16.2, 24.9, 38.1]  \n",
    "\n",
    "# fit our example classifier to the data\n",
    "example_lr.fit(X, y)\n",
    "\n",
    "# print the score\n",
    "print(\"Score: {:.3f}\".format(example_lr.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so different from last week, right? \n",
    "\n",
    "The main change from last week is that today we won't use the `predict` function — we'll just check the `score` to see how well we can fit a model to the data given features and a target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, one other thing we want to do today is inspect the coefficients of our regression models. This is done like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.155]\n"
     ]
    }
   ],
   "source": [
    "coefficient = example_lr.coef_\n",
    "print(coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how to interpret this from lecture? The coefficient is the slope of the regression line. More specifically, this tells value tells us the average change in our dependent variable (`y`) for one-unit change in our independent variable (or attribute, `x`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "### Part 2: Introduction to the dataset\n",
    "\n",
    "Today we will be working with `HomesSoldHellerup.csv`. A Dataset of housing sales in Hellerup. Each row consists of a home that was sold and the columns represent different attributes of the home. The attributes (columns) are listed for you below:\n",
    "\n",
    "Attribute Information\n",
    "- 1) `Road name`: The name of the road\n",
    "- 2) `Road number`: The road number of the home\n",
    "- 3) `Type`: What type of home is it? (\"Apartment\", \"Villa\" etc.)\n",
    "- 4) `m2`: The area of the home given in square meters\n",
    "- 5) `build year`: The year the home was build\n",
    "- 6) `Zip code`: The zip code which the home lies within\n",
    "- 7) `City`: The city the home is located in\n",
    "- 8) `Date of sale`: The day the house was sold\n",
    "- 9) `Type of sale`: How was the home sold? \n",
    "- 10) `Price`: The final price of the home in DKK\n",
    "\n",
    "Let's see if we can use these attributes to fit a linear regression model capable of estimating the price of a home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 1</font>\n",
    "\n",
    "It's always a good idea to get an overview of the data we are about to work with. Start by reading the `HomesSoldHellerup.csv` file, using the `read_csv` method from `pandas`, and call the dataset `homes_df`. Then use the `value_counts()` method to check how many of each `Type` of home there is in the dataset. Then inspect the range of `Price`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Note that the separator in this dataset is a semicolon and not a comma, which is the default. So you need to specify this with a parameter in the `read_csv()` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "homes_df = pd.read_csv('HomesSoldHellerup.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lejlighed          1237\n",
       "Villa               742\n",
       "Rækkehus            174\n",
       "Stuehus               3\n",
       "Erhverv               2\n",
       "Døgninstitution       2\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check value counts for `Type`\n",
    "homes_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum price: 133333\n",
      "Maximum price: 50000000\n",
      "Range of prices: 49866667\n"
     ]
    }
   ],
   "source": [
    "# check the range of `Price`\n",
    "print(\"Minimum price:\", homes_df['Price'].min())\n",
    "print(\"Maximum price:\", homes_df['Price'].max())\n",
    "print(\"Range of prices:\", homes_df['Price'].max()-homes_df['Price'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Fitting a linear regression model to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 2</font>\n",
    "\n",
    "To use a regression model we need at least one attribute and one target varaiable. The target is what we wish to predict based on one or more attributes.  We are going to use Linear Regression using the `sklearn` library and we will therefore use much of the same syntax and functions as we did in week 3. \n",
    "\n",
    "Define your feature matrix `X` with the single feature, `m2`, which is the size of the home in square meters. Then define your target `y` as `Price` from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = homes_df[['m2']]\n",
    "y = homes_df['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 3</font>\n",
    "Let's fit a simple linear regression model to `X` and `y`. If you have defined them correctly, this will estimate a coefficient based on the linear relationship between the size of the home in square meters and the price it was sold for. It could also potentially be used to predict the selling price of a home.\n",
    "\n",
    "Try it. Fit a linear regression model to `X` and `y`, and report the score and the coefficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Check out the documentation on the `sklearn` site for the linear regression to get a better idea of how it works:* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a linear regression model to X and y \n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.305\n"
     ]
    }
   ],
   "source": [
    "# print the score\n",
    "print(\"Score: {:.3f}\".format(lr.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"score\" for this model? What measure is it exactly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The \"score\" is the coefficient of determination of the prediction, *R^2*. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36683.88180408]\n"
     ]
    }
   ],
   "source": [
    "# print the coefficient\n",
    "coefficient = lr.coef_\n",
    "print(coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this coefficient suggest about the relationship between `m2` and `Price`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** On average, price increases by DKK 36,683 for every extra square meter (!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Fitting a linear regression model to the data, with a categorical attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 4</font>\n",
    "Last week you learned how to make dummy variables from a categorical variable with the `get_dummies` method from the `pandas` library. Dummy variables are especially important for the implementation of regression models, so let's try it here.\n",
    "\n",
    "Build a linear regression model just like you did in Part 3, but re-define `X` to use only the `Type` of home as the attribute this time. Since this is a categorical attribute, you must first make dummy variables.\n",
    "\n",
    "Fit the model to `X` and `y`, then report and interpret the score and the coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type_Erhverv</th>\n",
       "      <th>Type_Lejlighed</th>\n",
       "      <th>Type_Rækkehus</th>\n",
       "      <th>Type_Stuehus</th>\n",
       "      <th>Type_Villa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type_Erhverv  Type_Lejlighed  Type_Rækkehus  Type_Stuehus  Type_Villa\n",
       "0             0               1              0             0           0\n",
       "1             0               1              0             0           0\n",
       "2             0               1              0             0           0\n",
       "3             0               1              0             0           0\n",
       "4             0               1              0             0           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-define X using the `Type` attribute\n",
    "X = pd.get_dummies(homes_df[['Type']], drop_first = True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.084\n"
     ]
    }
   ],
   "source": [
    "# print score\n",
    "print(\"Score: {:.3f}\".format(lr.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this score, is this model better or worse than the one you fit with `m2` as the attribute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** It's worse. 0.084 < 0.30, and we want to get close to 1.0 for *R^2* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to extract the regression coefficients, align them with the column names, and then print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type_Erhverv': 9252499.999999793, 'Type_Lejlighed': -3082904.4373485288, 'Type_Rækkehus': -1581394.6436782412, 'Type_Stuehus': -3410152.000000147, 'Type_Villa': -418120.711590397}\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients\n",
    "coefficients = lr.coef_\n",
    "\n",
    "# Get the names of the dummy variable columns\n",
    "column_names = X.columns\n",
    "\n",
    "# Create a dictionary with column names as keys and coefficients as values\n",
    "coef_dict = dict(zip(column_names, coefficients))\n",
    "\n",
    "# Print the dictionary\n",
    "print(coef_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret this? Why is there not just one coefficient value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Are your coefficients all identical? If so, you've been affected by the [\"dummy variable trap\"](https://www.statology.org/dummy-variable-trap/). Go back to where you used `get_dummies`, set the argument `drop_first = True`, and re-run your code.*  \n",
    "\n",
    "*The dummy variable trap generally does not affect a model's predictive performance (i.e., the `score` is not affected). However, when interpreting regression coefficients, we need to avoid multicollinearity — we don't want an attribute to be correlated with another, because then it's hard to distinguish the individual effects of the correlated attributes. If we straightforwardly create a dummy variable for each possible value of a categorical variable, then we often introduce multicollinearity (e.g., if we know that a property is a villa, then we also know that it's not an apartment, business, etc.).*\n",
    "\n",
    "*The most common way to avoid the dummy variable trap is to create `n-1` dummy variables for a categorical variable with `n` unique values. We do this by setting `drop_first = True` with the `get_dummies` method.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** There's a separate coefficient for each dummy variable you created because these are represented as separate terms in your regression equation. Each coefficient tells you how much `Price`is expected to change if the property is the corresponding `Type` relative to the model's intercept term. In this case the model's intercept term represents the baseline price for homes of type `Døgninstitution` (which was dropped). You can inspect the intercept term of your model with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7247500.0000001015"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Fitting a logistic regression model to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been predicting price as a continuous target variable. But let's say, for illustrative purposes, we only care about whether the price is above or below the median price of all the houses on the market. Maybe I want to brag to my friends about having a home that costs more than at least 50% of all homes... I'd be a horrible dinner guest, but this makes for a nice classification task, so let's go with it.\n",
    "\n",
    "# <font color='red'>TASK 5</font>\n",
    "\n",
    "Add a new column to your main dataset, `homes_df`, which labels instances where the price is below the median price as 0 (indicating a \"low\" price) and all other instances 1 (indicating a \"high\" price). Name the column `Price_binary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000000.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = homes_df['Price']. median()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_df['Price_binary'] = np.where(homes_df['Price']<k, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Road name', 'Road Number', 'Type', 'm2', 'Build Year', 'ZipCode',\n",
       "       'City', 'Date of Sale', 'Type of Sale', 'Price', 'Price_binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 6</font>\n",
    "Now we have a binary, categorical variable that we want to predict: `Price_binary`. So, we no longer have a regression task on our hand, but a classification task. For this we'll use logistic regression.\n",
    "\n",
    "Implement a logistic regression model that uses `m2` as an attribute and `Price_binary` as a target variable. Fit the model to `X` and `y`, then report the score and the coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = homes_df[['m2']]\n",
    "y = homes_df['Price_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.831\n"
     ]
    }
   ],
   "source": [
    "#print score\n",
    "print(\"Score: {:.3f}\".format(logr.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"score\" for this logistic regression model? What measure is it exactly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The mean accuracy on the given data. This is more meaningful when doing a train-test split and evaluating on test data, but here it shows how the fitted sigmoid curve doesn't achieve perfect accuracy even on the data it's trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03555657]]\n"
     ]
    }
   ],
   "source": [
    "#print coefficient\n",
    "coefficient = logr.coef_\n",
    "print(coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret this coefficient? What does it tell us? Remember, it's a bit more confusing than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** the change in the *log-odds ratio* for y per unit change in x; the change in log odds of a house having a \"high\" price for each. \n",
    "\n",
    "When exponentiated, this becomes the change in the *odds ratio* for y per unit change in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03619627]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = np.exp(coefficient)\n",
    "odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the above tells us that, on average, for an increase of 1 square meter in size, the odds that the house will have a \"high\" price is 1.036 — the odds increase a little bit (a 3.6% increase). An odds ratio of 1.00 would mean absolutely no effect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "**That's it for this week! Next week we'll build regression models with multiple attributes and see how well our models generalize.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
