{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06: k-nearest neighbors\n",
    "\n",
    "Welcome to the sixth exercise for Applied Machine Learning. \n",
    "\n",
    "Your objectives for this session are to: \n",
    "- understand and apply feature scaling as an extra preprocessing step, \n",
    "- implement `KNeighborsRegressor`, and\n",
    "- tune model hyperparameters with `GridSearchCV`.\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data exploration and feature engineering\n",
    "\n",
    "We will again be looking at `HomesSoldHellerup.csv`, so the data is already familar to you if you did the exercises over the last two weeks. But, instead of using parametric models to predict `price`, today we'll use *instance-based learning*.\n",
    "\n",
    "Let's start by importing our libraries and exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset and inspect the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df = pd.read_csv('HomesSoldHellerup.csv', sep=';')\n",
    "homes_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the column names and the first five instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Road name</th>\n",
       "      <th>Road Number</th>\n",
       "      <th>Type</th>\n",
       "      <th>m2</th>\n",
       "      <th>Build Year</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>City</th>\n",
       "      <th>Date of Sale</th>\n",
       "      <th>Type of Sale</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>54</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>20-07-15</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>87</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>12-05-15</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>2815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>63</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>29-12-10</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>54</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>10-04-12</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>63</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>04-02-12</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1435000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Road name Road Number       Type  m2  Build Year  ZipCode      City  \\\n",
       "0  Tuborgvej            54  Lejlighed  54        1932     2900  Hellerup   \n",
       "1  Tuborgvej            54  Lejlighed  87        1932     2900  Hellerup   \n",
       "2  Tuborgvej            54  Lejlighed  63        1932     2900  Hellerup   \n",
       "3  Tuborgvej            54  Lejlighed  54        1932     2900  Hellerup   \n",
       "4  Tuborgvej            54  Lejlighed  63        1932     2900  Hellerup   \n",
       "\n",
       "  Date of Sale Type of Sale    Price  \n",
       "0     20-07-15    Alm. Salg  1700000  \n",
       "1     12-05-15    Alm. Salg  2815000  \n",
       "2     29-12-10    Alm. Salg  1575000  \n",
       "3     10-04-12    Alm. Salg  1340000  \n",
       "4     04-02-12    Alm. Salg  1435000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the columns has the `Date of Sale` with the exact date the house was sold. It seems unlikely that many houses would sell on the exact same date, and the date format can be tricky to work with.\n",
    "\n",
    "Let's see how many unique values there are in `Date of Sale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df['Date of Sale'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1218 unique dates across the 2160 totals instances suggests that `Date of Sale` is a *high-cardinality* attribute: it contains a large number of unique values relative to the total number of instances, which can make it challenging for machine learning models to use effectively.\n",
    "\n",
    "But, there could still be useful information in the `Date of Sale`. For example, maybe homes sell for more in summer than in winter, or maybe homes sell for more in recent years relative to older years. So, to make use of such information, we could do some feature engineering.\n",
    "\n",
    "Use the code below to create a `Year of Sale` feature by extracting the year from the `Date of Sale` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_df['Year of Sale'] = homes_df['Date of Sale'].apply(lambda x: '20' + x.split('-')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that there's the new `Year of Sale` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Road name</th>\n",
       "      <th>Road Number</th>\n",
       "      <th>Type</th>\n",
       "      <th>m2</th>\n",
       "      <th>Build Year</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>City</th>\n",
       "      <th>Date of Sale</th>\n",
       "      <th>Type of Sale</th>\n",
       "      <th>Price</th>\n",
       "      <th>Year of Sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>54</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>20-07-15</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1700000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>87</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>12-05-15</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>2815000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>63</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>29-12-10</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1575000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>54</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>10-04-12</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1340000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuborgvej</td>\n",
       "      <td>54</td>\n",
       "      <td>Lejlighed</td>\n",
       "      <td>63</td>\n",
       "      <td>1932</td>\n",
       "      <td>2900</td>\n",
       "      <td>Hellerup</td>\n",
       "      <td>04-02-12</td>\n",
       "      <td>Alm. Salg</td>\n",
       "      <td>1435000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Road name Road Number       Type  m2  Build Year  ZipCode      City  \\\n",
       "0  Tuborgvej            54  Lejlighed  54        1932     2900  Hellerup   \n",
       "1  Tuborgvej            54  Lejlighed  87        1932     2900  Hellerup   \n",
       "2  Tuborgvej            54  Lejlighed  63        1932     2900  Hellerup   \n",
       "3  Tuborgvej            54  Lejlighed  54        1932     2900  Hellerup   \n",
       "4  Tuborgvej            54  Lejlighed  63        1932     2900  Hellerup   \n",
       "\n",
       "  Date of Sale Type of Sale    Price Year of Sale  \n",
       "0     20-07-15    Alm. Salg  1700000         2015  \n",
       "1     12-05-15    Alm. Salg  2815000         2015  \n",
       "2     29-12-10    Alm. Salg  1575000         2010  \n",
       "3     10-04-12    Alm. Salg  1340000         2012  \n",
       "4     04-02-12    Alm. Salg  1435000         2012  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can also see in the data shown above is that there are different types of variables in the dataset. For example, `Road name`, `Type`, `City`, and `Type of Sale` are all categorical variables, whereas `m2`, `Build Year`, and `Year of Sale` are numeric. \n",
    "\n",
    "Use the code below to inspect the variable type assigned to each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Road name       object\n",
       "Road Number     object\n",
       "Type            object\n",
       "m2               int64\n",
       "Build Year       int64\n",
       "ZipCode          int64\n",
       "City            object\n",
       "Date of Sale    object\n",
       "Type of Sale    object\n",
       "Price            int64\n",
       "Year of Sale    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Year of Sale`, the feature we just added ourselves, is currently considered as an `object` (i.e., a categorical variable). Use the code below to change it to `int64` (i.e., a continuous, numeric variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_df['Year of Sale'] = homes_df['Year of Sale'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some descriptive statistics for the continuous variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m2</th>\n",
       "      <th>Build Year</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Price</th>\n",
       "      <th>Year of Sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2.160000e+03</td>\n",
       "      <td>2160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>137.582870</td>\n",
       "      <td>1941.846296</td>\n",
       "      <td>2920.328241</td>\n",
       "      <td>5.214775e+06</td>\n",
       "      <td>2012.676389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>67.275942</td>\n",
       "      <td>33.952880</td>\n",
       "      <td>309.679072</td>\n",
       "      <td>4.470072e+06</td>\n",
       "      <td>1.700720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>1.333330e+05</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>1919.000000</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>2.450000e+06</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>1933.000000</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>6.600000e+06</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>5.000000e+07</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                m2   Build Year      ZipCode         Price  Year of Sale\n",
       "count  2160.000000  2160.000000  2160.000000  2.160000e+03   2160.000000\n",
       "mean    137.582870  1941.846296  2920.328241  5.214775e+06   2012.676389\n",
       "std      67.275942    33.952880   309.679072  4.470072e+06      1.700720\n",
       "min      37.000000  1850.000000  2900.000000  1.333330e+05   2010.000000\n",
       "25%      86.000000  1919.000000  2900.000000  2.450000e+06   2011.000000\n",
       "50%     124.000000  1933.000000  2900.000000  4.000000e+06   2013.000000\n",
       "75%     170.000000  1960.000000  2900.000000  6.600000e+06   2014.000000\n",
       "max     570.000000  2015.000000  8800.000000  5.000000e+07   2015.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, notice how the attributes have different scales. For example, `m2` has a mean of 138 and ranges between 37 and 570, whereas `Build Year` mean of 1942 and ranges between 1850 and 2015. That makes sense given what the variables represent, but it could affect the performance of an instance-based learning algorithm, which rely on measures of similarity or distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Feature scaling\n",
    "\n",
    "Now that we've taken a look at our data and done a little feature engineering, it's time to make a train-test split. Then, once we've put aside a test set, we can do some feature scaling to address the issue of varying scales to suit an instance-based learning algorithm like `KNeighborsRegressor`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 1</font>\n",
    "\n",
    "Define your feature matrix `X` and target `y`. \n",
    "\n",
    "Create `X` with all the available attributes, except for `Date of Sale`, from which we already extracted the year to create the new attrubte, `Year of Sale`. \n",
    "\n",
    "`y` should be the `Price` of a home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(homes_df.drop(columns=['Date of Sale', 'Price']))\n",
    "y = homes_df['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the code below to make a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in addition to our unscaled feature matrices, `X_train` and `X_test`, let's use the `StandardScaler` to standardize the scales of the attributes. \n",
    "\n",
    "`StandardScaler` standardizes the scales across features by removing the mean and scaling to unit variance. For example, for each `m2` value, `StandardScaler` will re-scale that value by subtracting the mean `m2` and then dividing that difference by the standard deviation of `m2`. This can be useful because it centers all variables 0. However, `StandardScaler` is sensitive to outliers.\n",
    "\n",
    "Use the code below to apply `StandardScaler` *separately* to the `X_train` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # define the scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train) # apply to the training feature matrix\n",
    "X_test_scaled = scaler.transform(X_test) # apply to the testing feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `StandardScaler`, let's also try out `RobustScaler` so we can check if different scaling methods affect model performance.\n",
    "\n",
    "`RobustScaler` applies a different standardization by substracting the median (instead of the mean) and then divides by the inter-quartile range (instead of the standard deviation). In effect, this means `RobustScaler` is less sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 2</font>\n",
    "\n",
    "Apply `RobustScaler` to the `X_train` and `X_test` to create `X_train_robust` and `X_test_robust`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler() # define the scaler\n",
    "X_train_robust = robust_scaler.fit_transform(X_train) # apply to the training feature matrix\n",
    "X_test_robust = robust_scaler.transform(X_test) # apply to the testing feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Implementing `KNeighborsRegressor`\n",
    "\n",
    "Now that we have three different kinds of feature matrices:\n",
    "* `X_train` and `X_test` have the original features without any scaling,\n",
    "* `X_train_scaled` and `X_test_scaled` have the features with `StandardScaler`, and\n",
    "* `X_train_robust` and `X_test_robust` have the features with `RobustScaler`.\n",
    "\n",
    "Let's experiment and see which kind of scaling leads to the best results with `KNeighborsRegressor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 3</font>\n",
    "\n",
    "Fit a `KNeighborsRegressor` to `X_train` and `y_train` and define it as `knn`. Then print the model's training and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.663\n",
      "Score on test set: 0.580\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "print(\"Score on training set: {:.3f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Score on test set: {:.3f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 4</font>\n",
    "\n",
    "Fit a `KNeighborsRegressor` to `X_train_scaled` and `y_train` and define it as `knn_scaled`. Then print the model's training and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scaled = KNeighborsRegressor()\n",
    "knn_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.663\n",
      "Score on test set: 0.485\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "print(\"Score on training set: {:.3f}\".format(knn_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Score on test set: {:.3f}\".format(knn_scaled.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 5</font>\n",
    "\n",
    "Fit a `KNeighborsRegressor` to `X_train_robust` and `y_train` and define it as `knn_robust`. Then print the model's training and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_robust = KNeighborsRegressor()\n",
    "knn_robust.fit(X_train_robust, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.783\n",
      "Score on test set: 0.753\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "print(\"Score on training set: {:.3f}\".format(knn_robust.score(X_train_robust, y_train)))\n",
    "print(\"Score on test set: {:.3f}\".format(knn_robust.score(X_test_robust, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 6</font>\n",
    "\n",
    "Which kind of feature scaling led to the best performance with `KNeighborsRegressor`? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Robust scaling leads to the best performance. This is because instance-based learning algorithms like `KNeighborsRegressor` can be negatively affected by varying scales across attributes. Then the question is: which type of scaling is best? In this dataset, there are some outliers (see plot below), so `RobustScaler` outperforms `StandardScaler`. But ultimately, we only know for sure by experimenting with different scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(homes_df['m2'])\n",
    "plt.title('Boxplot of m2')\n",
    "plt.xticks([])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Tuning hyperparameters with `GridSearchCV`\n",
    "\n",
    "From our experiment above, we learned which scaling method was best... but can we improve performance even further?\n",
    "\n",
    "Let's see if tuning hyperparameters helps. With k-nearest neighbor models we can tune things like the number of neighbors to consider for the final prediction (`n_neighbors`), whether all neighbors should be weighed equally (`weights`), and the distance metric used (`metric` and `p`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to set up a parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 10, 20, 30, 40, 50, 60], # what should we set k to? \n",
    "    'weights': ['uniform', 'distance'], # uniform weighting vs. distance weighting\n",
    "    'p': [1, 2], # 1 for manhattan vs. 2 for euclidean distance\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TASK 7</font>\n",
    "\n",
    "Use `GridSearchCV` to figure out what the optimal hyperparameter settings are for `knn_robust`. Define the grid search as `grid_search`.\n",
    "\n",
    "*HINT: Check out the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for how to implement `GridSearchCV`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END n_neighbors=1, p=1, weights=uniform;, score=(train=0.999, test=0.707) total time=   0.1s\n",
      "[CV 2/5] END n_neighbors=1, p=1, weights=uniform;, score=(train=0.999, test=0.515) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=1, p=1, weights=uniform;, score=(train=0.999, test=0.363) total time=   0.1s\n",
      "[CV 4/5] END n_neighbors=1, p=1, weights=uniform;, score=(train=0.999, test=0.612) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=1, p=1, weights=uniform;, score=(train=1.000, test=0.527) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=1, p=1, weights=distance;, score=(train=0.999, test=0.707) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=1, p=1, weights=distance;, score=(train=0.999, test=0.515) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=1, p=1, weights=distance;, score=(train=0.999, test=0.363) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=1, p=1, weights=distance;, score=(train=0.999, test=0.612) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=1, p=1, weights=distance;, score=(train=1.000, test=0.527) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=1, p=2, weights=uniform;, score=(train=0.999, test=0.665) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=1, p=2, weights=uniform;, score=(train=0.999, test=0.499) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=1, p=2, weights=uniform;, score=(train=0.999, test=0.380) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=1, p=2, weights=uniform;, score=(train=0.999, test=0.588) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=1, p=2, weights=uniform;, score=(train=1.000, test=0.510) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=1, p=2, weights=distance;, score=(train=0.999, test=0.665) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=1, p=2, weights=distance;, score=(train=0.999, test=0.499) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=1, p=2, weights=distance;, score=(train=0.999, test=0.380) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=1, p=2, weights=distance;, score=(train=0.999, test=0.588) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=1, p=2, weights=distance;, score=(train=1.000, test=0.510) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=5, p=1, weights=uniform;, score=(train=0.763, test=0.734) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=5, p=1, weights=uniform;, score=(train=0.773, test=0.719) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=5, p=1, weights=uniform;, score=(train=0.816, test=0.469) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=5, p=1, weights=uniform;, score=(train=0.790, test=0.651) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=5, p=1, weights=uniform;, score=(train=0.780, test=0.607) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.804) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.731) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.477) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.668) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.623) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=5, p=2, weights=uniform;, score=(train=0.742, test=0.728) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=5, p=2, weights=uniform;, score=(train=0.782, test=0.610) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=5, p=2, weights=uniform;, score=(train=0.801, test=0.509) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=5, p=2, weights=uniform;, score=(train=0.787, test=0.621) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=5, p=2, weights=uniform;, score=(train=0.787, test=0.612) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.791) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.626) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.513) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.633) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.627) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.696, test=0.736) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.753, test=0.536) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.725, test=0.678) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.719, test=0.601) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.802) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.697) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.543) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.706) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.633) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.697, test=0.704) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.734, test=0.649) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.739, test=0.581) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.725, test=0.639) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.719, test=0.617) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.774) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.656) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.586) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.663) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.647) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.589, test=0.613) total time=   0.1s\n",
      "[CV 2/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.640, test=0.579) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.628, test=0.520) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.620, test=0.533) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.616, test=0.555) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.784) total time=   0.1s\n",
      "[CV 2/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.664) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.575) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.702) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.639) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.592, test=0.585) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.636, test=0.591) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.615, test=0.568) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.620, test=0.495) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.618, test=0.544) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.745) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.652) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.654) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.627) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=30, p=1, weights=uniform;, score=(train=0.523, test=0.505) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=30, p=1, weights=uniform;, score=(train=0.560, test=0.519) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=30, p=1, weights=uniform;, score=(train=0.539, test=0.511) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=30, p=1, weights=uniform;, score=(train=0.545, test=0.435) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=30, p=1, weights=uniform;, score=(train=0.532, test=0.497) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=30, p=1, weights=distance;, score=(train=1.000, test=0.758) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=30, p=1, weights=distance;, score=(train=1.000, test=0.643) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=30, p=1, weights=distance;, score=(train=1.000, test=0.605) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=30, p=1, weights=distance;, score=(train=1.000, test=0.679) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=30, p=1, weights=distance;, score=(train=1.000, test=0.623) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=30, p=2, weights=uniform;, score=(train=0.517, test=0.471) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=30, p=2, weights=uniform;, score=(train=0.555, test=0.524) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=30, p=2, weights=uniform;, score=(train=0.517, test=0.532) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=30, p=2, weights=uniform;, score=(train=0.539, test=0.421) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=30, p=2, weights=uniform;, score=(train=0.531, test=0.477) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=30, p=2, weights=distance;, score=(train=1.000, test=0.702) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=30, p=2, weights=distance;, score=(train=1.000, test=0.638) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=30, p=2, weights=distance;, score=(train=1.000, test=0.638) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=30, p=2, weights=distance;, score=(train=1.000, test=0.645) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=30, p=2, weights=distance;, score=(train=1.000, test=0.601) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=40, p=1, weights=uniform;, score=(train=0.476, test=0.432) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=40, p=1, weights=uniform;, score=(train=0.497, test=0.461) total time=   0.1s\n",
      "[CV 3/5] END n_neighbors=40, p=1, weights=uniform;, score=(train=0.480, test=0.496) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=40, p=1, weights=uniform;, score=(train=0.495, test=0.396) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=40, p=1, weights=uniform;, score=(train=0.477, test=0.460) total time=   0.1s\n",
      "[CV 1/5] END n_neighbors=40, p=1, weights=distance;, score=(train=1.000, test=0.729) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=40, p=1, weights=distance;, score=(train=1.000, test=0.621) total time=   0.1s\n",
      "[CV 3/5] END n_neighbors=40, p=1, weights=distance;, score=(train=1.000, test=0.615) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=40, p=1, weights=distance;, score=(train=1.000, test=0.675) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=40, p=1, weights=distance;, score=(train=1.000, test=0.611) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=40, p=2, weights=uniform;, score=(train=0.469, test=0.412) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=40, p=2, weights=uniform;, score=(train=0.490, test=0.466) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=40, p=2, weights=uniform;, score=(train=0.466, test=0.515) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=40, p=2, weights=uniform;, score=(train=0.494, test=0.396) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=40, p=2, weights=uniform;, score=(train=0.471, test=0.456) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=40, p=2, weights=distance;, score=(train=1.000, test=0.671) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=40, p=2, weights=distance;, score=(train=1.000, test=0.620) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=40, p=2, weights=distance;, score=(train=1.000, test=0.637) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=40, p=2, weights=distance;, score=(train=1.000, test=0.639) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=40, p=2, weights=distance;, score=(train=1.000, test=0.601) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.448, test=0.386) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.460, test=0.426) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.440, test=0.467) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.461, test=0.373) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.438, test=0.437) total time=   0.1s\n",
      "[CV 1/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.706) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.606) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.604) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.669) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.447, test=0.377) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.464, test=0.424) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.438, test=0.499) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.467, test=0.392) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.451, test=0.432) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.647) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.592) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.628) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.636) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.583) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=60, p=1, weights=uniform;, score=(train=0.425, test=0.358) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=60, p=1, weights=uniform;, score=(train=0.431, test=0.392) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=60, p=1, weights=uniform;, score=(train=0.415, test=0.454) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=60, p=1, weights=uniform;, score=(train=0.437, test=0.370) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=60, p=1, weights=uniform;, score=(train=0.415, test=0.423) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=60, p=1, weights=distance;, score=(train=1.000, test=0.688) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=60, p=1, weights=distance;, score=(train=1.000, test=0.593) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=60, p=1, weights=distance;, score=(train=1.000, test=0.603) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=60, p=1, weights=distance;, score=(train=1.000, test=0.665) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=60, p=1, weights=distance;, score=(train=1.000, test=0.591) total time=   0.1s\n",
      "[CV 1/5] END n_neighbors=60, p=2, weights=uniform;, score=(train=0.428, test=0.357) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=60, p=2, weights=uniform;, score=(train=0.444, test=0.401) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=60, p=2, weights=uniform;, score=(train=0.419, test=0.484) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=60, p=2, weights=uniform;, score=(train=0.450, test=0.384) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=60, p=2, weights=uniform;, score=(train=0.434, test=0.420) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=60, p=2, weights=distance;, score=(train=1.000, test=0.630) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=60, p=2, weights=distance;, score=(train=1.000, test=0.574) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=60, p=2, weights=distance;, score=(train=1.000, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=60, p=2, weights=distance;, score=(train=1.000, test=0.630) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=60, p=2, weights=distance;, score=(train=1.000, test=0.575) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 5, 10, 20, 30, 40, 50, 60],\n",
       "                         &#x27;p&#x27;: [1, 2], &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 5, 10, 20, 30, 40, 50, 60],\n",
       "                         &#x27;p&#x27;: [1, 2], &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': [1, 5, 10, 20, 30, 40, 50, 60],\n",
       "                         'p': [1, 2], 'weights': ['uniform', 'distance']},\n",
       "             return_train_score=True, scoring='r2', verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=knn_robust,  # the model being tuned\n",
    "                           param_grid=param_grid,  # dictionary of parameter values to search over\n",
    "                           cv=5,  # number of folds to use\n",
    "                           scoring='r2',  # evaluation metric\n",
    "                           return_train_score=True,  # whether to return training scores in the output.\n",
    "                           verbose=3)  # controls the verbosity of the output (i.e., how much output to print)\n",
    "\n",
    "# fit the model with training data X_train_robust and target y_train\n",
    "grid_search.fit(X_train_robust, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to print the best hyperparameter settings found, and the scores for `best_knn`, the `KNeighborsRegressor` with tuned hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter settings found:  {'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameter settings found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 1.000\n",
      "Score on test set: 0.751\n"
     ]
    }
   ],
   "source": [
    "best_knn = grid_search.best_estimator_\n",
    "print(\"Score on training set: {:.3f}\".format(best_knn.score(X_train_robust, y_train)))\n",
    "print(\"Score on test set: {:.3f}\".format(best_knn.score(X_test_robust, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did tuning help much in this case? Maybe... or maybe not so much in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus section: Including scaling methods in `GridSearchCV`\n",
    "\n",
    "In this notebook, we applied different scalers to the feature matrix one at a time for the sake of demonstration. However, you can also include different scalers *within* a tuning method like `GridSearchCV` to find the optimal configuration of scaler + hyperparameters all in one go. The code below shows you how to do this by creating a modelling `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.742, test=0.482) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.770, test=0.399) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.759, test=0.457) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.824, test=0.652) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.855, test=0.513) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.835, test=0.637) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.770, test=0.432) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.719, test=0.598) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.773, test=0.607) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.683) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.502) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.564) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.711) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.520) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.636) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.444) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.630) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.597) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.705, test=0.409) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.752, test=0.354) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.725, test=0.312) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.829, test=0.558) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.846, test=0.567) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.837, test=0.643) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.768, test=0.293) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.714, test=0.570) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.744, test=0.581) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.624) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.461) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.437) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.606) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.569) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.640) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.323) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.615) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=3, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.571) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.561, test=0.363) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.598, test=0.327) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.561, test=0.368) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.730, test=0.683) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.795, test=0.591) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.757, test=0.654) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.717, test=0.419) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.645, test=0.601) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.659, test=0.604) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.678) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.490) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.565) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.732) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.594) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.667) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.471) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.665) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.626) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.486, test=0.261) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.563, test=0.285) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.517, test=0.278) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.742, test=0.657) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.777, test=0.619) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.761, test=0.642) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.715, test=0.383) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.591, test=0.594) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.602, test=0.560) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.606) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.478) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.498) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.694) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.618) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.655) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.421) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.670) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=6, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.585) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.434, test=0.320) total time=   0.2s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.403, test=0.319) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.372, test=0.220) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.686, test=0.667) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.691, test=0.549) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.670, test=0.625) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.645, test=0.434) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.544, test=0.567) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.552, test=0.554) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.604) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.513) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.508) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.627) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.674) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.503) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.693) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.630) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.259, test=0.090) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.280, test=0.185) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.255, test=0.095) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.685, test=0.629) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.672, test=0.575) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.672, test=0.615) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.607, test=0.407) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.492, test=0.484) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.509, test=0.488) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.526) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.492) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.454) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.681) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.636) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.660) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.462) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.674) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=12, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.595) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.355, test=0.322) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.342, test=0.315) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.359, test=0.258) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.556, test=0.528) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.543, test=0.500) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.544, test=0.517) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.509, test=0.386) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.439, test=0.455) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.441, test=0.472) total time=   0.2s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.565) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.523) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.472) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.683) total time=   0.2s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.661) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.648) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.515) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.681) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.616) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.301, test=0.258) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.270, test=0.242) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.215, test=0.092) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.566, test=0.504) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.528, test=0.520) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.543, test=0.492) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.483, test=0.358) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.407, test=0.386) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.398, test=0.421) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.518) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.474) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.329) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.638) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.668) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.611) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.476) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.654) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=24, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.589) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.350, test=0.314) total time=   0.3s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.263, test=0.249) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.273, test=0.243) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.437, test=0.375) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.427, test=0.425) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.423, test=0.430) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.414, test=0.307) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.356, test=0.386) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.371, test=0.396) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.578) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.510) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.462) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.605) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.639) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.600) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.479) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.651) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.589) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.225, test=0.202) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.221, test=0.202) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.089, test=0.020) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.441, test=0.382) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.426, test=0.461) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.450, test=0.429) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.397, test=0.303) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.346, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.354, test=0.374) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.467) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.448) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.248) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.568) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.631) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.567) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.460) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.629) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=48, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.567) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.251, test=0.217) total time=   0.2s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.183, test=0.163) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.123, test=0.123) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.362, test=0.290) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.338, test=0.356) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.342, test=0.365) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.352, test=0.265) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.309, test=0.341) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=1, knn__weights=uniform, scaler=passthrough;, score=(train=0.315, test=0.351) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.520) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.459) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.381) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.526) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.585) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.546) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.447) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.608) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=1, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.557) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.108, test=0.106) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=0.100, test=0.073) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=StandardScaler();, score=(train=-0.007, test=-0.030) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.376, test=0.299) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.341, test=0.375) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=RobustScaler();, score=(train=0.356, test=0.372) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.354, test=0.269) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.309, test=0.343) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=2, knn__weights=uniform, scaler=passthrough;, score=(train=0.316, test=0.355) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.381) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.344) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=StandardScaler();, score=(train=1.000, test=0.199) total time=   0.0s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.486) total time=   0.1s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.564) total time=   0.1s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=RobustScaler();, score=(train=1.000, test=0.523) total time=   0.1s\n",
      "[CV 1/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.435) total time=   0.0s\n",
      "[CV 2/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.598) total time=   0.0s\n",
      "[CV 3/3] END knn__n_neighbors=96, knn__p=2, knn__weights=distance, scaler=passthrough;, score=(train=1.000, test=0.545) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;knn&#x27;, KNeighborsRegressor())]),\n",
       "             param_grid={&#x27;knn__n_neighbors&#x27;: [3, 6, 12, 24, 48, 96],\n",
       "                         &#x27;knn__p&#x27;: [1, 2],\n",
       "                         &#x27;knn__weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;],\n",
       "                         &#x27;scaler&#x27;: [StandardScaler(), RobustScaler(),\n",
       "                                    &#x27;passthrough&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;knn&#x27;, KNeighborsRegressor())]),\n",
       "             param_grid={&#x27;knn__n_neighbors&#x27;: [3, 6, 12, 24, 48, 96],\n",
       "                         &#x27;knn__p&#x27;: [1, 2],\n",
       "                         &#x27;knn__weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;],\n",
       "                         &#x27;scaler&#x27;: [StandardScaler(), RobustScaler(),\n",
       "                                    &#x27;passthrough&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;r2&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knn&#x27;, KNeighborsRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('knn', KNeighborsRegressor())]),\n",
       "             param_grid={'knn__n_neighbors': [3, 6, 12, 24, 48, 96],\n",
       "                         'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance'],\n",
       "                         'scaler': [StandardScaler(), RobustScaler(),\n",
       "                                    'passthrough']},\n",
       "             return_train_score=True, scoring='r2', verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# define the pipeline with a placeholder scaler and the KNN regressor\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Placeholder scaler\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# define the parameter grid to include different scalers and KNN parameters\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(),  RobustScaler(), 'passthrough'],  # different scaling methods (`passthrough` means no scaling)\n",
    "    'knn__n_neighbors': [3, 6, 12, 24, 48, 96],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__p': [1, 2],\n",
    "}\n",
    "\n",
    "# set up GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    return_train_score=True,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "#fit the model with the original training data (without prior scaling)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter settings found:  {'knn__n_neighbors': 12, 'knn__p': 1, 'knn__weights': 'distance', 'scaler': RobustScaler()}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameter settings found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "**That's it for this week! Next week we'll try out some unsupervised learning techniquea.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
